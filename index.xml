<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Justin Nguyen / Software Engineer</title><link>https://www.justinnuwin.com/</link><description>Recent content on Justin Nguyen / Software Engineer</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>© 2020 Justin Nguyen</copyright><lastBuildDate>Tue, 22 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://www.justinnuwin.com/index.xml" rel="self" type="application/rss+xml"/><item><title>IRIS Flight Software Development</title><link>https://www.justinnuwin.com/projects/iris-rover/</link><pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/projects/iris-rover/</guid><description>Github
I am currently developing the C&amp;amp;DH flight software for IRIS, CMU&amp;rsquo;s Lunar Rover. The flight software uses NASA JPL&amp;rsquo;s F-Prime flight-software framework on top of FreeRTOS. The C&amp;amp;DH is a TI Hercules Safety-Microcontroller.
Links: Github</description></item><item><title>Lawrence Livermore National Lab</title><link>https://www.justinnuwin.com/experience/llnl-2020/</link><pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/llnl-2020/</guid><description>I originally interned at LLNL over the summer of 2017 (click hear to learn more about my group), and joined part-time during university to support the software side of the project longer-term. I am continuing to develop vision algorithms for scientific measurements, but I am also working on streamlining our team&amp;rsquo;s workflow by using the latest workflow automation tools like Dagster.
Over the past 2 years working for the Film Scanning and Re-analysis project I have added several new measurement tools to our measurement tool written in Python.</description></item><item><title>Evaluation of ASR in Musical Environments</title><link>https://www.justinnuwin.com/projects/asr-music-semester-project/</link><pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/projects/asr-music-semester-project/</guid><description>Github
ASR is used heavily in eyes-busy or hands-busy situations and often time the user may be speaking over noise. My peers and I are particularly interested in how music effects ASR decoding. We use several music datasets of varied genre or broken-down instrumentation to allow us to perform in-depth anaysis of how different aspects of music influences speech recognizer&amp;rsquo;s performance. We then train a new model from what we have learned to see if we could improve the original model&amp;rsquo;s performance.</description></item><item><title>Embedded LS-PIV for Measuring Stream Flows</title><link>https://www.justinnuwin.com/projects/lspiv-semester-project/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/projects/lspiv-semester-project/</guid><description>Bitbucket not currently public
The USGS measures stream flows since they are critical for long-term tracking and modeling/forecasting to ensure that federal water priorities and responsibilities can be met and that the nation’s rivers canbe effectively managed. Recently, the USGS has been looking at non-contact methods of collection this data which would allow USGS scientists to gather data more safely and possibly without even going in to the field. One such method is large-scale particle image velocimetry (LS-PIV).</description></item><item><title>Denoising EEG Signals</title><link>https://www.justinnuwin.com/projects/denoising-eeg-semester-project/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/projects/denoising-eeg-semester-project/</guid><description>Github
EEGs are extremely interesting to the signal processing world as the signals from them are high dimensional and localized spatially, spectrally, and temporally. These signals are extremely low amplitude and artifacts appear in the measured signal due to normal human processes like blinking, breathing, and moving; or noise can appear due to the external factors such as line noise or sound in the room. My peers and I implement Viola&amp;rsquo;s ICA CorrMap procedure to denoise EEGs, but rather than retreiving EEG artifacts in-situ, we use Cho&amp;rsquo;s EEG dataset which separately records subjects in both rest states and performing various &amp;lsquo;noisy&amp;rsquo; actions prior to a motor imagery trial.</description></item><item><title>Cal Poly CubeSat Lab (PolySat)</title><link>https://www.justinnuwin.com/experience/polysat-2020/</link><pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/polysat-2020/</guid><description>I was heavily involved in the Cal Poly CubeSat Lab (PolySat) during my undergraduate. While working there for 4 years, I have worked on many CubeSat missions in a variety of roles throughout various mission lifetimes. I list out my accomplishmets and various projects below. I also interned at JPL, working on the MarCO CubeSat which was highly relavent to my experience at the Cal Poly CubeSat Lab.
Electrical Engineer 2016 - 2020</description></item><item><title>Cal Poly Autonomous Vehicle Security Group</title><link>https://www.justinnuwin.com/experience/cpavsec-2020/</link><pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/cpavsec-2020/</guid><description>The Cal Poly Autonomous Vehicle Security Group is headed by Dr. Bruce DeBruhl who is involved in security research for autonomous vehicles, IOT devices, and all things networked. The projects I have worked on in this group have been primarily focused towards the security of platoons of autonomous vehicles. Vehicle platoons require extensive communication to stay cohesive and ensure that no collisions occur. The two paradigms that vehicles communicate are vehicle-to-vehicle (V2V) using a protocol like DSRC or vehicle-to-infrastructure (V2I) usually using cellular infrastructure like 4G-LTE and 5G.</description></item><item><title>potatOS</title><link>https://www.justinnuwin.com/projects/potatos/</link><pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/projects/potatos/</guid><description>Github
I developed an x86_64 operating system and kernel from scratch. The OS has virtual memory and threading implemented.
Links: Github</description></item><item><title>Autonomous Navigation System for Mapping &amp; Traversing Rugged Terrain</title><link>https://www.justinnuwin.com/projects/cp-capstone/</link><pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/projects/cp-capstone/</guid><description>Github
The Northrop Grumman Collaboration Project (NGCP) is a project-club at Cal Poly that participates in engineering challenges posed by Northrop Grumman. The collaboration project is with Northrop Grumman, in addition to Cal Poly Pomona with whom the work for the engineering challenge is split with. The 2019 school year had a new mission which was a rugged-terrain rescue mission. My peers and I were tasked with with sensing and intelligence for one of their new vehicles.</description></item><item><title>NASA Jet Propulsion Laboratory (JPL)</title><link>https://www.justinnuwin.com/experience/jpl-2018/</link><pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/jpl-2018/</guid><description>After 1.5 years working at the Cal Poly CubeSat Lab I had the opportunity to intern at JPL to operate the MarCO CubeSats. MarCO is a pair of CubeSats that were launched with NASA&amp;rsquo;s InSight Lander with the mission to:
Relay InSight&amp;rsquo;s Entry, Descent, and Landing (EDL) data back to Earth in real-time Demonstrate the capabilities of the CubeSat form-factor in deep-space applications An interesting aspect of the MarCO mission is the level of involvement required due to systematic constraints on the mission.</description></item><item><title>Lawrence Livermore National Laboratory</title><link>https://www.justinnuwin.com/experience/llnl-2017/</link><pubDate>Mon, 11 Sep 2017 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/llnl-2017/</guid><description>During my first summer at Cal Poly, I interned at the Lawrence Livermore National Laboratory (LLNL) working on the Film Scanning and Re-Analysis Project headed by nuclear physicist Gregory Spriggs. The goal of the project is to digitize all the nuclear test films before they decay and reanalyze the results, as many of the results from the 1940s through the early 1960s were plagued with guesswork from the manual measurement process.</description></item><item><title>About</title><link>https://www.justinnuwin.com/homepage/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/homepage/about/</guid><description>Hi there! My name is Justin and I am currently a masters student at Carnegie Mellon University (CMU) in the Electrical and Computer Engineering Program (ECE). My interests are focused in embedded systems, machine learning, and computer architecture. I am working on several proejcts relating to edge-ML: how we can apply computationally intensive algorithms on resource-constrained embedded and mobile platforms. I am really passionate about collaborating with others to build amazing things, so browse my projects and feel free to reach out!</description></item><item><title>Contact</title><link>https://www.justinnuwin.com/homepage/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/homepage/contact/</guid><description>Feel free to reach out to me via these platforms:
Github Linkedin Twitter</description></item><item><title>Education</title><link>https://www.justinnuwin.com/homepage/education/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/homepage/education/</guid><description>Carnegie Mellon University M.S. Electrical and Computer Engineering • May 2020 - May 2021
Low Power code for IOT: Theory behind designing software (especially RTOS) to take advantage of &amp;ldquo;dark silicon&amp;rdquo; on embedded hardware to minimize energy use, thereby maximizing battery life. Speech Recognition and Understanding: Study how speech recognition systems model human speech using HMM+GMM, HMM+DNN, and end-to-end models. Implement simple HMM+GMM word recognizer and Listen, Attend, Spell (LAS) speech recognizer.</description></item><item><title>Skills</title><link>https://www.justinnuwin.com/homepage/skills/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/homepage/skills/</guid><description>Python and packages such as Numpy, Pandas, PyTorch, Keras, and Sklearn C/C++ for desktop and embedded applications with experience with libraries such as OpenCV, Boost, gRPC, ProtoBuf Proficient with machine learning techniques and libraries. Experience working with computer vision and speech recognition Hardware design PCB layout in Allegro and Altium Experience with embedded systems, particularly: ultra-low power systems, interconnect protocols, network protocols, and RF design View all my projects and experiences by tag to find something more specific.</description></item></channel></rss>