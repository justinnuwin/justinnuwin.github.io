<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Justin Nguyen / Software Engineer</title><link>https://www.justinnuwin.com/tags/machine-learning/</link><description>Recent content in machine learning on Justin Nguyen / Software Engineer</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Â© 2020 Justin Nguyen</copyright><lastBuildDate>Mon, 14 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://www.justinnuwin.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Evaluation of ASR in Musical Environments</title><link>https://www.justinnuwin.com/projects/asr-music-semester-project/</link><pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/projects/asr-music-semester-project/</guid><description>Github
ASR is used heavily in eyes-busy or hands-busy situations and often time the user may be speaking over noise. My peers and I are particularly interested in how music effects ASR decoding. We use several music datasets of varied genre or broken-down instrumentation to allow us to perform in-depth anaysis of how different aspects of music influences speech recognizer&amp;rsquo;s performance. We then train a new model from what we have learned to see if we could improve the original model&amp;rsquo;s performance.</description><content>&lt;p>&lt;a href="https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment">Github&lt;/a>&lt;/p>
&lt;p>ASR is used heavily in eyes-busy or hands-busy situations and often time the user may be speaking over noise.
My peers and I are particularly interested in how music effects ASR decoding.
We use several music datasets of varied genre or broken-down instrumentation to allow us to perform in-depth anaysis of how different aspects of music influences speech recognizer&amp;rsquo;s performance.
We then train a new model from what we have learned to see if we could improve the original model&amp;rsquo;s performance.&lt;/p>
&lt;img src="https://www.justinnuwin.com/projects/asr-music-semester-project/poster.png" alt="ASR Music Evaluation semester project poster" class="center" />
&lt;h4 id="links">Links:&lt;/h4>
&lt;ul>
&lt;li>&lt;a href="https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment/blob/master/18-781_Project_Report.pdf">Paper&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.justinnuwin.com/projects/asr-music-semester-project/poster.pdf">Poster&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment">Github&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment#releases">Data&lt;/a>&lt;/li>
&lt;/ul></content></item><item><title>Denoising EEG Signals</title><link>https://www.justinnuwin.com/projects/denoising-eeg-semester-project/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/projects/denoising-eeg-semester-project/</guid><description>Github
EEGs are extremely interesting to the signal processing world as the signals from them are high dimensional and localized spatially, spectrally, and temporally. These signals are extremely low amplitude and artifacts appear in the measured signal due to normal human processes like blinking, breathing, and moving; or noise can appear due to the external factors such as line noise or sound in the room. My peers and I implement Viola&amp;rsquo;s ICA CorrMap procedure to denoise EEGs, but rather than retreiving EEG artifacts in-situ, we use Cho&amp;rsquo;s EEG dataset which separately records subjects in both rest states and performing various &amp;lsquo;noisy&amp;rsquo; actions prior to a motor imagery trial.</description><content>&lt;p>&lt;a href="https://github.com/justinnuwin/Denoising-EEG-Signals">Github&lt;/a>&lt;/p>
&lt;p>EEGs are extremely interesting to the signal processing world as the signals from them are high dimensional and localized spatially, spectrally, and temporally.
These signals are extremely low amplitude and artifacts appear in the measured signal due to normal human processes like blinking, breathing, and moving; or noise can appear due to the external factors such as line noise or sound in the room.
My peers and I implement Viola&amp;rsquo;s ICA CorrMap procedure to denoise EEGs, but rather than retreiving EEG artifacts in-situ, we use Cho&amp;rsquo;s EEG dataset which separately records subjects in both rest states and performing various &amp;lsquo;noisy&amp;rsquo; actions prior to a motor imagery trial.
We use this data to try and denoise signals and try to devise a way to create a generalized artifact template that can be transferred from user to user.&lt;/p>
&lt;h4 id="links">Links:&lt;/h4>
&lt;ul>
&lt;li>&lt;a href="https://github.com/justinnuwin/Denoising-EEG-Signals/blob/master/18-797_Project_Report.pdf">Paper&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/justinnuwin/Denoising-EEG-Signals">Github&lt;/a>&lt;/li>
&lt;/ul></content></item><item><title>Cal Poly Autonomous Vehicle Security Group</title><link>https://www.justinnuwin.com/experience/cpavsec-2020/</link><pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/cpavsec-2020/</guid><description>The Cal Poly Autonomous Vehicle Security Group is headed by Dr. Bruce DeBruhl who is involved in security research for autonomous vehicles, IOT devices, and all things networked. The projects I have worked on in this group have been primarily focused towards the security of platoons of autonomous vehicles. Vehicle platoons require extensive communication to stay cohesive and ensure that no collisions occur. The two paradigms that vehicles communicate are vehicle-to-vehicle (V2V) using a protocol like DSRC or vehicle-to-infrastructure (V2I) usually using cellular infrastructure like 4G-LTE and 5G.</description><content>&lt;p>The Cal Poly Autonomous Vehicle Security Group is headed by Dr. Bruce DeBruhl who is involved in security research for autonomous vehicles, IOT devices, and all things networked.
The projects I have worked on in this group have been primarily focused towards the security of platoons of autonomous vehicles.
Vehicle platoons require extensive communication to stay cohesive and ensure that no collisions occur.
The two paradigms that vehicles communicate are vehicle-to-vehicle (V2V) using a protocol like DSRC or vehicle-to-infrastructure (V2I) usually using cellular infrastructure like 4G-LTE and 5G.&lt;/p>
&lt;h3 id="scale-platoon-project">Scale Platoon Project&lt;/h3>
&lt;p>The first year I joined the group, I provided assistance on a &lt;a href="https://digitalcommons.calpoly.edu/theses/2057">master&amp;rsquo;s thesis&lt;/a> and &lt;a href="https://digitalcommons.calpoly.edu/cpesp/249">senior project&lt;/a> both utilizing the same scale platoon platform using RC cars.
On these projects I developed real-time image processing pipelines to detect the other RC cars in the platoon and follow them.
This was done in C++ using the OpenCV library.
Due to the lack of imagery for &amp;ldquo;RC cars with electronics mounted on top&amp;rdquo;, pure image processing algorithms had to be used over machine learning or data-driven methods.
Some techniques used were distinct optical tracking markers, SIFT Features, optical flow, and sensor fusion were used to detect then track the movement of vehicles.
Since this had to run in real-time CUDA accelerated implementations were used along with the Nvidia Jetson platform.
In addition to the computer vision work, I also helped design the power distribution system for these vehicles and some of the microcontroller code to communicate with sensors like LiDAR, ultrasonic sensors, and IMUs.&lt;/p>
&lt;h3 id="autonomous-vehicle-simulator">Autonomous Vehicle Simulator&lt;/h3>
&lt;p>At the end of my third-year at Cal Poly, I started working on a new project in the group which was an autonomous vehicle simulator following the same line of thought for the scale platoon project, but not focusing on simulating life-sized vehicles on simulated roads.&lt;/p>
&lt;ul>
&lt;li>Develop vision-based lane following pipeline using OpenCV to allow simulated AV to drive on roads&lt;/li>
&lt;li>Develop autonomous perception and sensor fusion module for autonomous driving&lt;/li>
&lt;li>Design self-driving control architecture of simulated vehicle in residential environment using Microsoft Airsim and Unreal Engine&lt;/li>
&lt;li>Implement occupancy grid based local navigation system to navigate autonomous vehicle on residential streets&lt;/li>
&lt;li>Implement cascaded PID controller to drive autonomous vehicle&lt;/li>
&lt;/ul></content></item></channel></rss>