<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Experience on Justin Nguyen / Software Engineer</title><link>https://www.justinnuwin.com/experience/</link><description>Recent content in Experience on Justin Nguyen / Software Engineer</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Â© 2020 Justin Nguyen</copyright><lastBuildDate>Tue, 22 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://www.justinnuwin.com/experience/index.xml" rel="self" type="application/rss+xml"/><item><title>Lawrence Livermore National Lab</title><link>https://www.justinnuwin.com/experience/llnl-2020/</link><pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/llnl-2020/</guid><description>I originally interned at LLNL over the summer of 2017 (click hear to learn more about my group), and joined part-time during university to support the software side of the project longer-term. To facilitate me working at the national lab part-time during university I am contracted under J&amp;amp;A Film Preservation, a company that has been working with the Film Scanning and Re-Analysis Project for several years. I am continuing to develop vision algorithms for scientific measurements, but I am also working on streamlining our team&amp;rsquo;s workflow by using the latest workflow automation tools like Dagster.</description><content>&lt;p>&lt;a href="https://www.justinnuwin.com/experience/llnl-2017">I originally interned at LLNL over the summer of 2017 (click hear to learn more about my group)&lt;/a>, and joined part-time during university to support the software side of the project longer-term.
To facilitate me working at the national lab part-time during university I am contracted under J&amp;amp;A Film Preservation, a company that has been working with the Film Scanning and Re-Analysis Project for several years.
I am continuing to develop vision algorithms for scientific measurements, but I am also working on streamlining our team&amp;rsquo;s workflow by using the latest workflow automation tools like Dagster.&lt;/p>
&lt;p>Over the past 2 years working for the Film Scanning and Re-analysis project I have added several new measurement tools to our measurement tool written in Python.
These tools include &lt;strong>global-segmented&lt;/strong> film exposure measurement methods, and a a new fireball detection pipeline that I architected utilizing spectral analysis and temporal edge tracking.
I also added measurement statistics for all of the data our group generates using scikit-learn to better understand our measurements.
In addition, I have refactored our codebase to explicitly support both CLI and GUI (Tk) methods to run which will allow the team to programmatically re-analyze and update old results more easily.&lt;/p>
&lt;p>From the refactoring sprint, I was able to abstract our application logic to work well on both desktop environments for developing new codes and on HPC environments provided by Livermore Computing&amp;rsquo;s supercomputers.
Dagster, a workflow orchestration tool, ties our workflow together with its pipeline and asset management systems, and I developed a multithreaded image loader as a CPython module to further speed up our program&amp;rsquo;s analysis.&lt;/p></content></item><item><title>Cal Poly CubeSat Lab (PolySat)</title><link>https://www.justinnuwin.com/experience/polysat-2020/</link><pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/polysat-2020/</guid><description>I was heavily involved in the Cal Poly CubeSat Lab (PolySat) during my undergraduate. While working there for 4 years, I have worked on many CubeSat missions in a variety of roles throughout various mission lifetimes. I list out my accomplishmets and various projects below. I also interned at JPL, working on the MarCO CubeSat which was highly relavent to my experience at the Cal Poly CubeSat Lab.
Electrical Engineer 2016 - 2020</description><content>&lt;p>I was heavily involved in the &lt;a href="https://www.polysat.org">Cal Poly CubeSat Lab (PolySat)&lt;/a> during my undergraduate.
While working there for 4 years, I have worked on many CubeSat missions in a variety of roles throughout various mission lifetimes.
I list out my accomplishmets and various projects below.
I also interned at &lt;a href="https://www.justinnuwin.com/experience/jpl-2018">JPL, working on the MarCO CubeSat&lt;/a> which was highly relavent to my experience at the Cal Poly CubeSat Lab.&lt;/p>
&lt;h3 id="electrical-engineer">Electrical Engineer&lt;/h3>
&lt;p>&lt;strong>2016 - 2020&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Rigid and Flexible PCB design in OrCAD and Altium&lt;/li>
&lt;li>Lead electrical design reviews&lt;/li>
&lt;li>Design and test side panels and custom flat flex cables for 3 CubeSat missions (CP12-ExoCube2, CP14-ADE, C-SPOT)&lt;/li>
&lt;li>Assist in design and testing of payload interface boards and various peripheral electronics for 6 CubeSat missions (CP10-ISX, CP12-ExoCube2, CP14-ADE, CP15-Spinnacker3, Falcon, C-SPOT)&lt;/li>
&lt;li>Design updated ground support debugger for CubeSat flight computer utilizing USB&lt;/li>
&lt;li>Oversee electrical - software interface and functionality testing&lt;/li>
&lt;li>Test, verify, and validate flight electronic systems (Power, Communications, Command &amp;amp; Data Handling (C&amp;amp;DH))&lt;/li>
&lt;li>Develop and troubleshoot embedded Linux flight computer utilizing Atmel processor&lt;/li>
&lt;li>Tune and checkout flight UHF transceivers&lt;/li>
&lt;li>Tune antennas using VNA (vector network analyzer)&lt;/li>
&lt;li>Flight Assembly in Class 100,000 Clean Room&lt;/li>
&lt;li>Review and improve testing procedures&lt;/li>
&lt;li>Write documentation for assembly procedures, board modification procedures, and OrCAD design tutorials&lt;/li>
&lt;li>Train new members in electrical system design, high speed digital design, and PCB design using OrCAD and Altium&lt;/li>
&lt;/ul>
&lt;h3 id="groundstation-lead">Groundstation Lead&lt;/h3>
&lt;p>&lt;strong>2017 - 2019&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Organize operations team for various flight missions: CP-7 DAVE, CP-10 ISX, CP-12 ExoCube II&lt;/li>
&lt;li>Train new members on groundstation infrastructure and operation&lt;/li>
&lt;li>Maintain Cal Poly&amp;rsquo;s 3 UHF/VHF ground stations used for operating in-orbit spacecraft&lt;/li>
&lt;li>Coordinate ground station team for spacecraft operations&lt;/li>
&lt;li>Manage ground station projects (Ground Station In a Box, Local RF Noise Measurement Project)&lt;/li>
&lt;/ul>
&lt;h3 id="lab-manager">Lab Manager&lt;/h3>
&lt;p>&lt;strong>2018 - 2020&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Consult for the start up of new CubeSat programs (LigerSat- Phnom Penh, Cambodia; Bronco Space-Cal Poly Pamona)&lt;/li>
&lt;li>Lead lab restructuring and redevelopment effort to overhaul training, systems engineering, V&amp;amp;V (verification and validation) checkpoints, hardware development workflows, internal receiving inspections, internal review processes, documentation processes, procedure development, and management and team structures to improve lab efficiency and success&lt;/li>
&lt;li>Manage CubeSat missions and projects in Cal Poly CubeSat Lab (CP-7 DAVE, CP-12 ExoCube 2, CP-14 ADE, CP-15 Spinnacker3, SWIS, NIAC, Pocket Rocket, Sensor Development)&lt;/li>
&lt;li>Coordinate design and production timelines to ensure on-time delivery&lt;/li>
&lt;li>Review discipline team processes to maximize quality&lt;/li>
&lt;li>Delegate tasks with project and discipline leads to ensure balanced workload throughout engineering teams&lt;/li>
&lt;li>Improve on system level and electronic subsystem design for early mission designs sharing core hardware used across Cal Poly CubeSat Lab missions&lt;/li>
&lt;li>Meet with individual teams and team members to assist with testing and assembly tasks and scheduling&lt;/li>
&lt;li>Improved lab recruiting process&lt;/li>
&lt;li>Interim CP-12 ExoCube 2 Mission Manager&lt;/li>
&lt;/ul></content></item><item><title>Cal Poly Autonomous Vehicle Security Group</title><link>https://www.justinnuwin.com/experience/cpavsec-2020/</link><pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/cpavsec-2020/</guid><description>The Cal Poly Autonomous Vehicle Security Group is headed by Dr. Bruce DeBruhl who is involved in security research for autonomous vehicles, IOT devices, and all things networked. The projects I have worked on in this group have been primarily focused towards the security of platoons of autonomous vehicles. Vehicle platoons require extensive communication to stay cohesive and ensure that no collisions occur. The two paradigms that vehicles communicate are vehicle-to-vehicle (V2V) using a protocol like DSRC or vehicle-to-infrastructure (V2I) usually using cellular infrastructure like 4G-LTE and 5G.</description><content>&lt;p>The Cal Poly Autonomous Vehicle Security Group is headed by Dr. Bruce DeBruhl who is involved in security research for autonomous vehicles, IOT devices, and all things networked.
The projects I have worked on in this group have been primarily focused towards the security of platoons of autonomous vehicles.
Vehicle platoons require extensive communication to stay cohesive and ensure that no collisions occur.
The two paradigms that vehicles communicate are vehicle-to-vehicle (V2V) using a protocol like DSRC or vehicle-to-infrastructure (V2I) usually using cellular infrastructure like 4G-LTE and 5G.&lt;/p>
&lt;h3 id="scale-platoon-project">Scale Platoon Project&lt;/h3>
&lt;p>The first year I joined the group, I provided assistance on a &lt;a href="https://digitalcommons.calpoly.edu/theses/2057">master&amp;rsquo;s thesis&lt;/a> and &lt;a href="https://digitalcommons.calpoly.edu/cpesp/249">senior project&lt;/a> both utilizing the same scale platoon platform using RC cars.
On these projects I developed real-time image processing pipelines to detect the other RC cars in the platoon and follow them.
This was done in C++ using the OpenCV library.
Due to the lack of imagery for &amp;ldquo;RC cars with electronics mounted on top&amp;rdquo;, pure image processing algorithms had to be used over machine learning or data-driven methods.
Some techniques used were distinct optical tracking markers, SIFT Features, optical flow, and sensor fusion were used to detect then track the movement of vehicles.
Since this had to run in real-time CUDA accelerated implementations were used along with the Nvidia Jetson platform.
In addition to the computer vision work, I also helped design the power distribution system for these vehicles and some of the microcontroller code to communicate with sensors like LiDAR, ultrasonic sensors, and IMUs.&lt;/p>
&lt;h3 id="autonomous-vehicle-simulator">Autonomous Vehicle Simulator&lt;/h3>
&lt;p>At the end of my third-year at Cal Poly, I started working on a new project in the group which was an autonomous vehicle simulator following the same line of thought for the scale platoon project, but not focusing on simulating life-sized vehicles on simulated roads.&lt;/p>
&lt;ul>
&lt;li>Develop vision-based lane following pipeline using OpenCV to allow simulated AV to drive on roads&lt;/li>
&lt;li>Develop autonomous perception and sensor fusion module for autonomous driving&lt;/li>
&lt;li>Design self-driving control architecture of simulated vehicle in residential environment using Microsoft Airsim and Unreal Engine&lt;/li>
&lt;li>Implement occupancy grid based local navigation system to navigate autonomous vehicle on residential streets&lt;/li>
&lt;li>Implement cascaded PID controller to drive autonomous vehicle&lt;/li>
&lt;/ul></content></item><item><title>NASA Jet Propulsion Laboratory (JPL)</title><link>https://www.justinnuwin.com/experience/jpl-2018/</link><pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/jpl-2018/</guid><description>After 1.5 years working at the Cal Poly CubeSat Lab I had the opportunity to intern at JPL to operate the MarCO CubeSats. MarCO is a pair of CubeSats that were launched with NASA&amp;rsquo;s InSight Lander with the mission to:
Relay InSight&amp;rsquo;s Entry, Descent, and Landing (EDL) data back to Earth in real-time Demonstrate the capabilities of the CubeSat form-factor in deep-space applications An interesting aspect of the MarCO mission is the level of involvement required due to systematic constraints on the mission.</description><content>&lt;p>After 1.5 years &lt;a href="https://www.justinnuwin.com/experience/polysat-2020">working at the Cal Poly CubeSat Lab&lt;/a> I had the opportunity to intern at JPL to operate the &lt;a href="https://www.jpl.nasa.gov/cubesat/missions/marco.php">MarCO CubeSats&lt;/a>.
MarCO is a pair of CubeSats that were launched with NASA&amp;rsquo;s InSight Lander with the mission to:&lt;/p>
&lt;ul>
&lt;li>Relay InSight&amp;rsquo;s Entry, Descent, and Landing (EDL) data back to Earth in real-time&lt;/li>
&lt;li>Demonstrate the capabilities of the CubeSat form-factor in deep-space applications&lt;/li>
&lt;/ul>
&lt;p>An interesting aspect of the MarCO mission is the level of involvement required due to systematic constraints on the mission.
Unlike flagship missions which may have hundreds of personnel for operations alone, CubeSats are targeted for low-cost R&amp;amp;D, development, and operations.
To accomplish this JPL brought on many partners both in the development and the operations of MarCO.
&lt;a href="https://www.polysat.org/">Cal Poly and the CubeSat Lab&lt;/a> were selected to assist JPL with MarCO operations; this partnership consisted of two Cal Poly students who would intern at JPL over the duration of the mission to handle day-to-day operations and a larger team of students working from Cal Poly&amp;rsquo;s campus who would do long-term telemetry analysis and forecasting.
As an intern on the flight operations team, I interfaced the JPL operations team with the operations team at Cal Poly, in addition to my day-to-day duties: drafting and verifying uplink products, analyzing telemetry, and recommending future spacecraft activities.&lt;/p>
&lt;figure class="right" >
&lt;img src="https://www.justinnuwin.com/experience/jpl-2018/polysat-team.jpg" alt="PolySat summer students during MarCO mission" />
&lt;figcaption class="center" >Students working at the Cal Poly CubeSat Lab over the summer tour JPL while MarCO was cruising to Mars. Credit: Michael Fernandez&lt;/figcaption>
&lt;/figure>
&lt;p>The MarCO mission used NASA AMMOS AMPCS to handle the ground infrastructure and data management, which was easily accessible from the JPL campus, but it was not feasible to expose critical mission infrastructure externally, so I developed a lightweight data management system that could be more easily shared with Cal Poly.
The workflow I developed consisted of three parts:&lt;/p>
&lt;ul>
&lt;li>A HDF5 (and sqlite) database with an ingestion engine for pulling telemetry from JPL servers&lt;/li>
&lt;li>NASA OpenMCT which handled all data visualization&lt;/li>
&lt;li>A python client which interface with the telemetry database to query or update data with strict 2-way data binding protocols to ensure the sources of truth were maintained&lt;/li>
&lt;/ul>
&lt;p>In addition to the workflow for allowing external collaborators to access mission data, on the day-to-day side, many tools needed to be developed to streamline and automate more of the mission operations as the team matured and understood the idiosyncrasies of the spacecraft better.
Some of the tools I developed were:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Telemetry Quicklook&lt;/strong>: A service which aggregates spacecraft data and generates &amp;ldquo;quick-look&amp;rdquo; items in OpenMCT which summarizes spacecraft health.&lt;/li>
&lt;li>&lt;strong>Automatic Pass Report Generator&lt;/strong>: All spacecraft activities are planned and documented beforehand, but it proved laborious to annotate telemetry with specific events in these procedures, so this tool automatically collects telemetry generated during a procedure and generates a &amp;ldquo;pass report&amp;rdquo; (a pass is a term originally used for Earth-orbiting spacecraft when they would &amp;ldquo;pass&amp;rdquo; overhead) which was a nicely formatted pdf document which could be attached to the procedures and highlighted important telemetry during the activity. This tool was designed with Python and Pandoc.&lt;/li>
&lt;/ul>
&lt;img src="https://www.justinnuwin.com/experience/jpl-2018/marco-team-darkroom.jpg" alt="MarCO Operations Team in the SFOC &amp;#39;Dark Room&amp;#39;" class="center" />
&lt;p>If you would like to learn more about MarCO or InSight see these links:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.jpl.nasa.gov/cubesat/missions/marco.php">MarCO&amp;rsquo;s Website&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://solarsystem.nasa.gov/missions/mars-cube-one/in-depth/">In-depth details on MarCO&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.jpl.nasa.gov/news/press_kits/insight/">InSight Launch and Landing Press Kit&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>If you would like to learn more about CubeSats here are some helpful links:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.cubesat.org/">The CubeSat Organization (you can find developer documents here)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.nasa.gov/sites/default/files/atoms/files/nasa_csli_cubesat_101_508.pdf">CubeSats 101 by NASA CSLI&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.nasa.gov/mission_pages/cubesats/index.html">NASA CubeSat News&lt;/a>&lt;/li>
&lt;/ul></content></item><item><title>Lawrence Livermore National Laboratory</title><link>https://www.justinnuwin.com/experience/llnl-2017/</link><pubDate>Mon, 11 Sep 2017 00:00:00 +0000</pubDate><guid>https://www.justinnuwin.com/experience/llnl-2017/</guid><description>During my first summer at Cal Poly, I interned at the Lawrence Livermore National Laboratory (LLNL) working on the Film Scanning and Re-Analysis Project headed by nuclear physicist Gregory Spriggs. The goal of the project is to digitize all the nuclear test films before they decay and reanalyze the results, as many of the results from the 1940s through the early 1960s were plagued with guesswork from the manual measurement process.</description><content>&lt;p>During my first summer at Cal Poly, I interned at the Lawrence Livermore National Laboratory (LLNL) working on the &lt;a href="https://www.lanl.gov/discover/publications/national-security-science/2015-july/_assets/doc/NSS-jul2015-filmscanning.pdf">Film Scanning and Re-Analysis Project&lt;/a> headed by nuclear physicist Gregory Spriggs.
The goal of the project is to digitize all the nuclear test films before they decay and reanalyze the results, as many of the results from the 1940s through the early 1960s were plagued with guesswork from the manual measurement process.&lt;/p>
&lt;figure class="right" >
&lt;img src="https://www.justinnuwin.com/experience/llnl-2017/tesla28602_000037.png" alt="Frame from nuclear test film" />
&lt;figcaption class="center" >A frame from Operation Teapot (Tesla 28602). Credit LLNL Youtube Channel&lt;/figcaption>
&lt;/figure>
&lt;p>Shockwave analysis is one of the few methods used to determine the yield of a nuclear detonation.
To calculate the yield of these shots using the 1-D, spherical model developed by Taylor, an equivalent radius of the elliptical shockwave must be determined.
Armed with the digitized replicas of the original nuclear test films and the latest image processing tools, a methodology for segmenting the shockwave from the digitized film and measuring these shockwaves has been developed to quickly and accurately quantify the shape of these asymmetric shockwaves.
With a two-dimensional result from these asymmetric shockwaves, several methods are discussed to transform the final shockwave contour to an equivalent radius that can be used to determine the yield.&lt;/p>
&lt;figure class="center" >
&lt;img src="https://www.justinnuwin.com/experience/llnl-2017/exposure-adj.png" alt="Exposure adjustment results" />
&lt;figcaption class="center" >Optimized exposure LUTs derived from parameter search. First row contains the original cropped frames. The second row shows the waveforms (horizontal spectrogram) of the images in the first row. Middle row is the LUT's exposure curve. The final two rows are the adjusted frames and their respective waveforms.&lt;/figcaption>
&lt;/figure>
&lt;p>The pipeline I developed provides was developed in Python using the OpenCV library and can detect and accurately measure the shockwave and fireball with minimal user input.
I utilized the high performance computing cluster at LLNL to perform parameter search over different exposures-adjusting look up tables which could be applied to a film to &amp;ldquo;boost&amp;rdquo; the fireball&amp;rsquo;s signal.&lt;/p>
&lt;p>More detailed information about my project can be found at these links:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.justinnuwin.com/experience/llnl-2017/LLNL-TR-738324.pdf">Technical Report&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.justinnuwin.com/experience/llnl-2017/LLNL-POST-735703.pdf">Poster&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.justinnuwin.com/experience/llnl-2017/LLNL-PRES-738070.pdf">Presentation&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>If you would like to learn more about the science behind the nuclear tests see these links:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://youtu.be/c6W2suGacjQ">WIRED Video on the Nuclear Tests&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://youtu.be/tsOrRWzmmUU">Answering FAQs about the Nuclear Test Films&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://youtube.com/playlist?list=PLvGO_dWo8VfcmG166wKRy5z-GlJ_OQND5">Watch the recently-declassified original nuclear tests&lt;/a>&lt;/li>
&lt;/ul></content></item></channel></rss>